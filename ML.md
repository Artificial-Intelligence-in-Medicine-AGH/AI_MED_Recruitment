# Klasyczne metody uczenia maszynowego

PoniÅ¼ej znajdujÄ… siÄ™ krÃ³tkie opisy metod uczenia maszynowego, ktÃ³re mogÄ… byÄ‡ wykorzystane do rozwiÄ…zania zadania klasyfikacji. W razie potrzeby lepszego zrozumienia prosimy o zapoznanie siÄ™ z dokumentacjÄ… danej metody w bibliotece scikit-learn lub samodzielny reasearch.

## Drzewa decyzyjne (Decision Trees)

Metoda polegajÄ…ca na podejmowaniu decyzji w oparciu o kolejne pytania (podziaÅ‚y danych) w strukturze drzewa. KaÅ¼dy wÄ™zeÅ‚ odpowiada testowi na wybranej cesze, a kaÅ¼da gaÅ‚Ä…Åº reprezentuje wynik tego testu. Drzewa decyzyjne sÄ… proste do zrozumienia i interpretacji, ale mogÄ… Å‚atwo prowadziÄ‡ do przeuczenia (overfittingu).
<br/>
ğŸ“– Dokumentacja: [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)

## Lasy losowe (Random Forest)

Algorytm zespoÅ‚owy (ang. ensemble), ktÃ³ry buduje wiele drzew decyzyjnych na rÃ³Å¼nych losowych podzbiorach danych i cech. Wynik klasyfikacji jest okreÅ›lany na podstawie gÅ‚osowania wiÄ™kszoÅ›ciowego. Lasy losowe sÄ… bardziej odporne na przeuczenie niÅ¼ pojedyncze drzewa i zapewniajÄ… wysokÄ… skutecznoÅ›Ä‡.
<br/>
ğŸ“– Dokumentacja: [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)

## K-Nearest Neighbors (k-NN)

Algorytm oparty na podobieÅ„stwie. Nowa prÃ³bka jest klasyfikowana na podstawie klas `k` najbliÅ¼szych punktÃ³w w przestrzeni cech (mierzonej np. odlegÅ‚oÅ›ciÄ… euklidesowÄ…). Metoda jest prosta i skuteczna, ale bywa kosztowna obliczeniowo przy duÅ¼ych zbiorach danych.
<br/>
ğŸ“– Dokumentacja: [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)

## Support Vector Machine (SVM)

Metoda klasyfikacji polegajÄ…ca na znajdowaniu hiperpowierzchni (hiperpÅ‚aszczyzny), ktÃ³ra najlepiej oddziela klasy w przestrzeni cech. SVM stara siÄ™ maksymalizowaÄ‡ margines pomiÄ™dzy klasami, co zapewnia dobrÄ… zdolnoÅ›Ä‡ generalizacji. DziÄ™ki uÅ¼yciu funkcji jÄ…dra (kernel) moÅ¼na klasyfikowaÄ‡ dane nieliniowo.
<br/>
ğŸ“– Dokumentacja: [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)

## Regresja logistyczna (Logistic Regression)

Model probabilistyczny uÅ¼ywany do klasyfikacji binarnej. Szacuje prawdopodobieÅ„stwo przynaleÅ¼noÅ›ci prÃ³bki do danej klasy, a nastÄ™pnie klasyfikuje na podstawie progu (np. 0.5). Jest prostym i interpretowalnym modelem, czÄ™sto uÅ¼ywanym jako punkt odniesienia w klasyfikacji. Prekursor sieci neuronowych.
<br/>
ğŸ“– Dokumentacja: [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)

# Miary jakoÅ›ci klasyfikacji

Do oceny skutecznoÅ›ci modeli klasyfikacyjnych stosuje siÄ™ rÃ³Å¼ne metryki. NajczÄ™Å›ciej uÅ¼ywane to:

## Accuracy (DokÅ‚adnoÅ›Ä‡)

Odsetek poprawnych predykcji (zarÃ³wno pozytywnych, jak i negatywnych) wzglÄ™dem wszystkich prÃ³bek. Dobrze dziaÅ‚a przy zrÃ³wnowaÅ¼onych zbiorach danych, ale bywa mylÄ…cy przy niezbalansowanych klasach.
<br/>
ğŸ“– Dokumentacja: [accuracy\_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)

## Precision (Precyzja)

OkreÅ›la, jaki odsetek prÃ³bek zaklasyfikowanych jako pozytywne rzeczywiÅ›cie naleÅ¼y do klasy pozytywnej. Wysoka precyzja oznacza maÅ‚Ä… liczbÄ™ faÅ‚szywych alarmÃ³w (false positives).
<br/>
ğŸ“– Dokumentacja: [precision\_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)

## Recall (CzuÅ‚oÅ›Ä‡)

Pokazuje, jaki odsetek rzeczywistych przypadkÃ³w pozytywnych zostaÅ‚ poprawnie wykryty przez model. Wysoka czuÅ‚oÅ›Ä‡ oznacza maÅ‚Ä… liczbÄ™ przeoczonych przypadkÃ³w pozytywnych (false negatives).
<br/>
ğŸ“– Dokumentacja: [recall\_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)

## F1-score

Åšrednia harmoniczna precyzji i czuÅ‚oÅ›ci. WartoÅ›Ä‡ F1 dobrze rÃ³wnowaÅ¼y obie metryki i jest szczegÃ³lnie przydatna przy niezbalansowanych klasach.
<br/>
ğŸ“– Dokumentacja: [f1\_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)

# Macierz pomyÅ‚ek (Confusion Matrix)

Macierz pomyÅ‚ek pozwala zwizualizowaÄ‡ wyniki klasyfikacji, rozrÃ³Å¼niajÄ…c poprawne i bÅ‚Ä™dne decyzje modelu.

|                         | Rzeczywiste pozytywne | Rzeczywiste negatywne |
| ----------------------- | --------------------- | --------------------- |
| **Predykcja pozytywna** | True Positive (TP)    | False Positive (FP)   |
| **Predykcja negatywna** | False Negative (FN)   | True Negative (TN)    |

* **TP (True Positive)** â€“ poprawnie wykryte przypadki pozytywne.
* **TN (True Negative)** â€“ poprawnie wykryte przypadki negatywne.
* **FP (False Positive)** â€“ przypadki negatywne bÅ‚Ä™dnie zaklasyfikowane jako pozytywne.
* **FN (False Negative)** â€“ przypadki pozytywne bÅ‚Ä™dnie zaklasyfikowane jako negatywne.

Metryki oblicza siÄ™ na podstawie wartoÅ›ci z tej tabeli:

* Accuracy = (TP + TN) / (TP + TN + FP + FN)
* Precision = TP / (TP + FP)
* Recall = TP / (TP + FN)
* F1-score = 2 \* (Precision \* Recall) / (Precision + Recall)
<br/>
ğŸ“– Dokumentacja: [confusion\_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
